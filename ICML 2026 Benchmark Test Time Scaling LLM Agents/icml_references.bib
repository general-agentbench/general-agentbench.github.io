i@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}


@article{jin2025beneficial,
  title={Beneficial Reasoning Behaviors in Agentic Search and Effective Post-training to Obtain Them},
  author={Jin, Jiahe and Paladugu, Abhijay and Xiong, Chenyan},
  journal={arXiv preprint arXiv:2510.06534},
  year={2025}
}

@inproceedings{gu2024mamba,
  title={Mamba: Linear-time sequence modeling with selective state spaces},
  author={Gu, Albert and Dao, Tri},
  booktitle={First conference on language modeling},
  year={2024}
}

@inproceedings{yao2022react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik R and Cao, Yuan},
  booktitle={The eleventh international conference on learning representations},
  year={2022}
}

@article{liu2023agentbench,
  title={Agentbench: Evaluating llms as agents},
  author={Liu, Xiao and Yu, Hao and Zhang, Hanchen and Xu, Yifan and Lei, Xuanyu and Lai, Hanyu and Gu, Yu and Ding, Hangliang and Men, Kaiwen and Yang, Kejuan and others},
  journal={arXiv preprint arXiv:2308.03688},
  year={2023}
}

@article{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={68539--68551},
  year={2023}
}

@article{zhou2023webarena,
  title={Webarena: A realistic web environment for building autonomous agents},
  author={Zhou, Shuyan and Xu, Frank F and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Ou, Tianyue and Bisk, Yonatan and Fried, Daniel and others},
  journal={arXiv preprint arXiv:2307.13854},
  year={2023}
}

@article{yang2024sweagent,
  title={Swe-agent: Agent-computer interfaces enable automated software engineering},
  author={Yang, John and Jimenez, Carlos E and Wettig, Alexander and Lieret, Kilian and Yao, Shunyu and Narasimhan, Karthik and Press, Ofir},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={50528--50652},
  year={2024}
}

@article{qin2023toolllm,
  title={Toolllm: Facilitating large language models to master 16000+ real-world apis},
  author={Qin, Yujia and Liang, Shihao and Ye, Yining and Zhu, Kunlun and Yan, Lan and Lu, Yaxi and Lin, Yankai and Cong, Xin and Tang, Xiangru and Qian, Bill and others},
  journal={arXiv preprint arXiv:2307.16789},
  year={2023}
}

@article{wei2025browsecomp,
  title={Browsecomp: A simple yet challenging benchmark for browsing agents},
  author={Wei, Jason and Sun, Zhiqing and Papay, Spencer and McKinney, Scott and Han, Jeffrey and Fulford, Isa and Chung, Hyung Won and Passos, Alex Tachard and Fedus, William and Glaese, Amelia},
  journal={arXiv preprint arXiv:2504.12516},
  year={2025}
}

@article{jimenez2023swebench,
  title={Swe-bench: Can language models resolve real-world github issues?},
  author={Jimenez, Carlos E and Yang, John and Wettig, Alexander and Yao, Shunyu and Pei, Kexin and Press, Ofir and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2310.06770},
  year={2023}
}

@article{gou2025mind2web,
  title={Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge},
  author={Gou, Boyu and Huang, Zanming and Ning, Yuting and Gu, Yu and Lin, Michael and Qi, Weijian and Kopanev, Andrei and Yu, Botao and Guti{\'e}rrez, Bernal Jim{\'e}nez and Shu, Yiheng and others},
  journal={arXiv preprint arXiv:2506.21506},
  year={2025}
}

@article{he2024webvoyager,
  title={Webvoyager: Building an end-to-end web agent with large multimodal models},
  author={He, Hongliang and Yao, Wenlin and Ma, Kaixin and Yu, Wenhao and Dai, Yong and Zhang, Hongming and Lan, Zhenzhong and Yu, Dong},
  journal={arXiv preprint arXiv:2401.13919},
  year={2024}
}

@misc{terminalbench_2025,
      title={Terminal-Bench: A Benchmark for AI Agents in Terminal Environments}, 
      url={https://github.com/laude-institute/terminal-bench}, 
      author={The Terminal-Bench Team}, year={2025}, month={Apr}} 

@article{barres2025tau2,
  title={tau2-Bench: Evaluating Conversational Agents in a Dual-Control Environment},
  author={Barres, Victor and Dong, Honghua and Ray, Soham and Si, Xujie and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2506.07982},
  year={2025}
}

@article{wang2025mcpbench,
  title={Mcp-bench: Benchmarking tool-using llm agents with complex real-world tasks via mcp servers},
  author={Wang, Zhenting and Chang, Qi and Patel, Hemani and Biju, Shashank and Wu, Cheng-En and Liu, Quan and Ding, Aolin and Rezazadeh, Alireza and Shah, Ankit and Bao, Yujia and others},
  journal={arXiv preprint arXiv:2508.20453},
  year={2025}
}

@inproceedings{bai2025longbenchv2,
  title={Longbench v2: Towards deeper understanding and reasoning on realistic long-context multitasks},
  author={Bai, Yushi and Tu, Shangqing and Zhang, Jiajie and Peng, Hao and Wang, Xiaozhi and Lv, Xin and Cao, Shulin and Xu, Jiazheng and Hou, Lei and Dong, Yuxiao and others},
  booktitle={Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={3639--3664},
  year={2025}
}

@article{yen2024helmet,
  title={Helmet: How to evaluate long-context language models effectively and thoroughly},
  author={Yen, Howard and Gao, Tianyu and Hou, Minmin and Ding, Ke and Fleischer, Daniel and Izsak, Peter and Wasserblat, Moshe and Chen, Danqi},
  journal={arXiv preprint arXiv:2410.02694},
  year={2024}
}

@misc{openai_mrcr_2025,
  author       = {{OpenAI}},
  title        = {OpenAI MRCR: Long context multiple needle in a haystack benchmark},
  howpublished = {\url{https://huggingface.co/datasets/openai/mrcr}},
  year         = {2025},
  note         = {Hugging Face Datasets. Accessed: 2026-01-15}
}

@article{wang2024mathhay,
  title={Mathhay: An automated benchmark for long-context mathematical reasoning in llms},
  author={Wang, Lei and Dong, Shan and Xu, Yuhui and Dong, Hanze and Wang, Yalu and Saha, Amrita and Lim, Ee-Peng and Xiong, Caiming and Sahoo, Doyen},
  journal={arXiv preprint arXiv:2410.04698},
  year={2024}
}

@article{liang2025sweillusion,
  title={The SWE-Bench Illusion: When State-of-the-Art LLMs Remember Instead of Reason},
  author={Liang, Shanchao and Garg, Spandan and Moghaddam, Roshanak Zilouchian},
  journal={arXiv preprint arXiv:2506.12286},
  year={2025}
}

@inproceedings{yang2025100,
  title={100-LongBench: Are de facto Long-Context Benchmarks Literally Evaluating Long-Context Ability?},
  author={Yang, Van and Jin, Hongye and Zhong, Shaochen and Jiang, Song and Wang, Qifan and Chaudhary, Vipin and Han, Xiaotian},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2025},
  pages={17560--17576},
  year={2025}
}

@misc{kamradt_needlehaystack_2023,
  author       = {Gregory Kamradt},
  title        = {{LLMTest\_NeedleInAHaystack}: Needle In A Haystack -- Pressure Testing LLMs},
  howpublished = {\url{https://github.com/gkamradt/LLMTest_NeedleInAHaystack}},
  year         = {2023},
  note         = {GitHub repository. Accessed: 2026-01-15}
}

@misc{openai_swebench_verified_2024,
  author       = {{OpenAI}},
  title        = {Introducing {SWE}-bench Verified},
  howpublished = {\url{https://openai.com/index/introducing-swe-bench-verified/}},
  year         = {2024},
  month        = aug,
  note         = {OpenAI Blog. Updated: 2025-02-24. Accessed: 2026-01-15}
}

@inproceedings{muennighoff2025s1,
  title={s1: Simple test-time scaling},
  author={Muennighoff, Niklas and Yang, Zitong and Shi, Weijia and Li, Xiang Lisa and Fei-Fei, Li and Hajishirzi, Hannaneh and Zettlemoyer, Luke and Liang, Percy and Cand{\`e}s, Emmanuel and Hashimoto, Tatsunori B},
  booktitle={Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
  pages={20286--20332},
  year={2025}
}

@article{Aleithan2024SWEBenchPlus,
  title={SWE-Bench+: Enhanced Coding Benchmark for LLMs},
  author={Aleithan, Reem and others},
  journal={arXiv preprint arXiv:2410.06992},
  year={2024}
}

@article{Zhang2025SWEBenchGoesLive,
  title={SWE-bench Goes Live!},
  author={Zhang, Linghao and others},
  journal={arXiv preprint arXiv:2505.23419},
  year={2025}
}


@article{Yao2022WebShop,
  title={WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents},
  author={Yao, Shunyu and Chen, Howard and Yang, John and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2207.01206},
  year={2022}
}

@inproceedings{Deng2023Mind2Web,
  title={Mind2Web: Towards a Generalist Agent for the Web},
  author={Deng, Xiang and Gu, Yu and Zheng, Boyuan and Chen, Shijie and Stevens, Samuel and Wang, Boshi and Sun, Huan and Su, Yu},
  booktitle={NeurIPS Datasets and Benchmarks},
  year={2023}
}

@article{Anupam2025BrowserArena,
  title={BrowserArena: Evaluating LLM Agents on Real-World Web Navigation Tasks},
  author={Anupam, S. and others},
  journal={arXiv preprint arXiv:2510.02418},
  year={2025}
}

@inproceedings{Yoran2024AssistantBench,
  title={AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?},
  author={Yoran, Ori and others},
  booktitle={EMNLP},
  year={2024}
}

@article{Mialon2023GAIA,
  title={GAIA: A Benchmark for General AI Assistants},
  author={Mialon, Gr{\'e}goire and Fourrier, Cl{\'e}mentine and Swift, Craig and Wolf, Thomas and LeCun, Yann and Scialom, Thomas},
  journal={arXiv preprint arXiv:2311.12983},
  year={2023}
}

@inproceedings{Li2023APIBank,
  title={API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs},
  author={Li, Minghao and others},
  booktitle={EMNLP},
  year={2023},
  note={arXiv:2304.08244}
}

@inproceedings{Guo2024StableToolBench,
  title={StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models},
  author={Guo, Z. and others},
  booktitle={Findings of ACL},
  year={2024}
}

@article{Yao2024TauBench,
  title={$\\tau$-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains},
  author={Yao, Shunyu and others},
  journal={arXiv preprint arXiv:2406.12045},
  year={2024}
}

@article{Shen2023HuggingGPT,
  title={HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face},
  author={Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  journal={arXiv preprint arXiv:2303.17580},
  year={2023}
}

@article{Xie2023OpenAgents,
  title={OpenAgents: An Open Platform for Language Agents in the Wild},
  author={Xie, Tianbao and Zhou, Fan and Cheng, Zhoujun and Shi, Peng and Weng, Luoxuan and Liu, Yitao and others},
  journal={arXiv preprint arXiv:2310.10634},
  year={2023}
}

@article{Wu2023AutoGen,
  title={AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework},
  author={Wu, Qingyun and others},
  journal={arXiv preprint arXiv:2308.08155},
  year={2023}
}

@article{Wang2023Voyager,
  title={Voyager: An Open-Ended Embodied Agent with Large Language Models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}

@article{Wei2022CoT,
  title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc V. and Zhou, Denny},
  journal={arXiv preprint arXiv:2201.11903},
  year={2022}
}

@article{Wang2022SelfConsistency,
  title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@article{Yao2023ToT,
  title={Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L. and Cao, Yuan and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2305.10601},
  year={2023}
}

@article{Zhou2023LATS,
  title={Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models},
  author={Zhou, Andy and Yan, Kai and Shlapentokh-Rothman, Michal and Wang, Haohan and Wang, Yu-Xiong},
  journal={arXiv preprint arXiv:2310.04406},
  year={2023}
}

@article{Madaan2023SelfRefine,
  title={Self-Refine: Iterative Refinement with Self-Feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and others},
  journal={arXiv preprint arXiv:2303.17651},
  year={2023}
}

@article{Lightman2023VerifyStepByStep,
  title={Let's Verify Step by Step},
  author={Lightman, Hunter and others},
  journal={arXiv preprint arXiv:2305.20050},
  year={2023}
}

@inproceedings{
patil2025bfcl,
title={The Berkeley Function Calling Leaderboard ({BFCL}): From Tool Use to Agentic Evaluation of Large Language Models},
author={Shishir G Patil and Huanzhi Mao and Fanjia Yan and Charlie Cheng-Jie Ji and Vishnu Suresh and Ion Stoica and Joseph E. Gonzalez},
booktitle={Forty-second International Conference on Machine Learning},
year={2025},
url={https://openreview.net/forum?id=2GmDdhBdDk}
}


@article{rawles2024androidworld,
  title={Androidworld: A dynamic benchmarking environment for autonomous agents},
  author={Rawles, Christopher and Clinckemaillie, Sarah and Chang, Yifan and Waltz, Jonathan and Lau, Gabrielle and Fair, Marybeth and Li, Alice and Bishop, William and Li, Wei and Campbell-Ajala, Folawiyo and others},
  journal={arXiv preprint arXiv:2405.14573},
  year={2024}
}

@article{xie2024osworld,
  title={Osworld: Benchmarking multimodal agents for open-ended tasks in real computer environments},
  author={Xie, Tianbao and Zhang, Danyang and Chen, Jixuan and Li, Xiaochuan and Zhao, Siheng and Cao, Ruisheng and Hua, Toh J and Cheng, Zhoujun and Shin, Dongchan and Lei, Fangyu and others},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={52040--52094},
  year={2024}
}

@article{shinn2023reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={8634--8652},
  year={2023}
}

@misc{microsoftagent, 
title={Microsoft/agent-framework: A framework for building, orchestrating and deploying AI agents and multi-agent workflows with support for Python and .NET.}, 
url={https://github.com/microsoft/agent-framework}, 
author={Microsoft}, 
language={en},
year={2025}, 
month={Apr}
}

@misc{claudeagent,
  author       = {{Anthropic}},
  title        = {Building Agents with the {Claude} Agent {SDK}},
howpublished = {\url{https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk}},
  year         = {2025},
  month        = sep,
  note         = {Accessed: 2026-01-29}
}

@misc{openaiagent,
title={Introducing AgentKit}, 
url={https://openai.com/index/introducing-agentkit/}, 
author={OpenAI},
year={2025},
month={Oct},
language={en}
}

@misc{Qwenagent, 
title={QwenLM/Qwen-Agent: Agent framework and applications built upon Qwen>=3.0, featuring Function Calling, MCP, Code Interpreter, RAG, Chrome extension, etc.}, 
url={https://github.com/QwenLM/Qwen-Agent}, 
year={2023},
month={Sep},
author={QwenLM},
language={en} }

@misc{gemini,
title={Gemini}, 
url={https://deepmind.google/models/gemini/}, 
author={Google Deepmind},
year={2025},
month={Nov},
language={en}
}

@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@misc{openai2024learning-to-reason,
  author       = {{OpenAI}},
  title        = {Learning to reason with LLMs},
  year         = {2024},
  month        = sep,
  howpublished = {\url{https://openai.com/index/learning-to-reason-with-llms/}},
  note         = {Accessed: 2026-01-28}
}

@misc{kavukcuoglu2025gemini2available,
  author       = {Kavukcuoglu, Koray and {on behalf of the Gemini team}},
  title        = {Gemini 2.0 is now available to everyone},
  year         = {2025},
  month        = feb,
  howpublished = {\url{https://blog.google/innovation-and-ai/models-and-research/google-deepmind/gemini-model-updates-february-2025/}},
  note         = {The Keyword (Google Blog). Accessed: 2026-01-28}
}

@article{hosseini2024v,
  title={V-star: Training verifiers for self-taught reasoners},
  author={Hosseini, Arian and Yuan, Xingdi and Malkin, Nikolay and Courville, Aaron and Sordoni, Alessandro and Agarwal, Rishabh},
  journal={arXiv preprint arXiv:2402.06457},
  year={2024}
}

@inproceedings{wang2024math,
  title={Math-shepherd: Verify and reinforce llms step-by-step without human annotations},
  author={Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, Runxin and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Yu and Sui, Zhifang},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={9426--9439},
  year={2024}
}

@article{gao2024agentscope,
  title={Agentscope: A flexible yet robust multi-agent platform},
  author={Gao, Dawei and Li, Zitao and Pan, Xuchen and Kuang, Weirui and Ma, Zhijian and Qian, Bingchen and Wei, Fei and Zhang, Wenhao and Xie, Yuexiang and Chen, Daoyuan and others},
  journal={arXiv preprint arXiv:2402.14034},
  year={2024}
}

@inproceedings{chen2023agentverse,
  title={Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors},
  author={Chen, Weize and Su, Yusheng and Zuo, Jingwei and Yang, Cheng and Yuan, Chenfei and Chan, Chi-Min and Yu, Heyang and Lu, Yaxi and Hung, Yi-Hsin and Qian, Chen and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@misc{moonshotai2026kimi-k25,
  author       = {{Moonshot AI}},
  title        = {Kimi K2.5: Visual Agentic Intelligence},
  year         = {2026},
  month        = jan,
  day          = {27},
  howpublished = {\url{https://www.kimi.com/blog/kimi-k2-5.html}},
  note         = {Accessed: 2026-01-28}
}


@misc{claudeskills,
  author       = {{Anthropic}},
  title        = {Building agents with Skills: Equipping agents for specialized work},
  year         = {2026},
  month        = jan,
  day          = {22},
  url = {https://claude.com/blog/building-agents-with-skills-equipping-agents-for-specialized-work},
}

@article{xi2023rise,
  title={The Rise and Potential of Large Language Model Based Agents: A Survey},
  author={Xi, Zhiheng and Chen, Wenxiang and Guo, Xin and He, Wei and Ding, Yiwen and Hong, Boyang and Zhang, Ming and Wang, Junzhe and Jin, Senjie and Zhou, Enyu and others},
  journal={arXiv preprint arXiv:2309.07864},
  year={2023}
}

@article{luo2025large,
  title={Large language model agent: A survey on methodology, applications and challenges},
  author={Luo, Junyu and Zhang, Weizhi and Yuan, Ye and Zhao, Yusheng and Yang, Junwei and Gu, Yiyang and Wu, Bohan and Chen, Binqi and Qiao, Ziyue and Long, Qingqing and others},
  journal={arXiv preprint arXiv:2503.21460},
  year={2025}
}

@article{patil2024gorilla,
  title={Gorilla: Large language model connected with massive apis},
  author={Patil, Shishir G and Zhang, Tianjun and Wang, Xin and Gonzalez, Joseph E},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={126544--126565},
  year={2024}
}

@article{parmar2025plangen,
  title={PlanGEN: A Multi-Agent Framework for Generating Planning and Reasoning Trajectories for Complex Problem Solving},
  author={Parmar, Mihir and Liu, Xin and Goyal, Palash and Chen, Yanfei and Le, Long and Mishra, Swaroop and Mobahi, Hossein and Gu, Jindong and Wang, Zifeng and Nakhost, Hootan and others},
  journal={arXiv preprint arXiv:2502.16111},
  year={2025}
}

@inproceedings{
erdogan2025planandact,
title={Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks},
author={Lutfi Eren Erdogan and Hiroki Furuta and Sehoon Kim and Nicholas Lee and Suhong Moon and Gopala Anumanchipalli and Kurt Keutzer and Amir Gholami},
booktitle={Forty-second International Conference on Machine Learning},
year={2025},
url={https://openreview.net/forum?id=ybA4EcMmUZ}
}

@article{wang2023plan,
  title={Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models},
  author={Wang, Lei and Xu, Wanyu and Lan, Yihuai and Hu, Zhiqiang and Lan, Yunshi and Lee, Roy Ka-Wei and Lim, Ee-Peng},
  journal={arXiv preprint arXiv:2305.04091},
  year={2023}
}

@article{liu2023fingpt,
  title={Fingpt: Democratizing internet-scale data for financial large language models},
  author={Liu, Xiao-Yang and Wang, Guoxuan and Yang, Hongyang and Zha, Daochen},
  journal={arXiv preprint arXiv:2307.10485},
  year={2023}
}

@inproceedings{yue2024clinicalagent,
  title={Clinicalagent: Clinical trial multi-agent system with large language model-based reasoning},
  author={Yue, Ling and Xing, Sixue and Chen, Jintai and Fu, Tianfan},
  booktitle={Proceedings of the 15th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
  pages={1--10},
  year={2024}
}

@article{snell2024scaling,
  title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal={arXiv preprint arXiv:2408.03314},
  year={2024}
}

@article{brown2024large,
  title={Large language monkeys: Scaling inference compute with repeated sampling},
  author={Brown, Bradley and Juravsky, Jordan and Ehrlich, Ryan and Clark, Ronald and Le, Quoc V and R{\'e}, Christopher and Mirhoseini, Azalia},
  journal={arXiv preprint arXiv:2407.21787},
  year={2024}
}

@article{zelikman2024quiet,
  title={Quiet-star: Language models can teach themselves to think before speaking},
  author={Zelikman, Eric and Harik, Georges and Shao, Yijia and Jayasiri, Varuna and Haber, Nick and Goodman, Noah D},
  journal={arXiv preprint arXiv:2403.09629},
  year={2024}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@misc{mcp,
  author       = {{Anthropic}},
  title        = {Introducing the Model Context Protocol},
  year         = {2024},
  month        = nov,
  day          = {25},
  url = {https://www.anthropic.com/news/model-context-protocol},
}


@article{liu2025deepseekv3.2,
  title={Deepseek-v3. 2: Pushing the frontier of open large language models},
  author={Liu, Aixin and Mei, Aoxue and Lin, Bangcai and Xue, Bing and Wang, Bingxuan and Xu, Bingzheng and Wu, Bochao and Zhang, Bowei and Lin, Chaofan and Dong, Chen and others},
  journal={arXiv preprint arXiv:2512.02556},
  year={2025}
}

@article{yang2025qwen3,
  title={Qwen3 technical report},
  author={Yang, An and Li, Anfeng and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Gao, Chang and Huang, Chengen and Lv, Chenxu and others},
  journal={arXiv preprint arXiv:2505.09388},
  year={2025}
}

@misc{qwen3next,
  author       = {{Qwen Team, Alibaba Inc.}},
  title        = {{Qwen3-Next}: Towards Ultimate Training \& Inference Efficiency},
  howpublished = {\url{https://qwen.ai/blog?id=4074cca80393150c248e508aa62983f9cb7d27cd}},
  year         = {2025},
  month        = sep,
  note         = {Accessed: 2026-01-29}
}

@article{comanici2025gemini,
  title={Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities},
  author={Comanici, Gheorghe and Bieber, Eric and Schaekermann, Mike and Pasupat, Ice and Sachdeva, Noveen and Dhillon, Inderjit and Blistein, Marcel and Ram, Ori and Zhang, Dan and Rosen, Evan and others},
  journal={arXiv preprint arXiv:2507.06261},
  year={2025}
}

@techreport{openai_gpt5,
  author       = {{OpenAI}},
  title        = {GPT-5 System Card},
  institution  = {OpenAI},
  year         = {2025},
  month        = aug,
  url          = {https://cdn.openai.com/gpt-5-system-card.pdf},
}

@misc{anthropic2025claude45,
  author       = {{Anthropic}},
  title        = {Introducing Claude Sonnet 4.5},
  howpublished = {\url{https://www.anthropic.com/news/claude-sonnet-4-5}},
  year         = {2025},
  month        = sep,
  day = {29},
  note         = {Accessed: 2026-01-29}
}

@article{mei2025survey,
  title={A survey of context engineering for large language models},
  author={Mei, Lingrui and Yao, Jiayu and Ge, Yuyao and Wang, Yiwei and Bi, Baolong and Cai, Yujun and Liu, Jiazhi and Li, Mingyu and Li, Zhong-Zhi and Zhang, Duzhen and others},
  journal={arXiv preprint arXiv:2507.13334},
  year={2025}
}

@article{zhang2025agentic,
  title={Agentic context engineering: Evolving contexts for self-improving language models},
  author={Zhang, Qizheng and Hu, Changran and Upasani, Shubhangi and Ma, Boyuan and Hong, Fenglu and Kamanuru, Vamsidhar and Rainton, Jay and Wu, Chen and Ji, Mengmeng and Li, Hanchen and others},
  journal={arXiv preprint arXiv:2510.04618},
  year={2025}
}

@misc{claudecontexxt,
  author       = {{Anthropic}},
  title        = {Effective context engineering for AI agents},
  howpublished = {\url{https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents}},
  year         = {2025},
  month        = sep,
  day = {29},
  note         = {Accessed: 2026-01-29}
}

@article{kovcisky2018narrativeqa,
  title={The narrativeqa reading comprehension challenge},
  author={Ko{\v{c}}isk{\`y}, Tom{\'a}{\v{s}} and Schwarz, Jonathan and Blunsom, Phil and Dyer, Chris and Hermann, Karl Moritz and Melis, G{\'a}bor and Grefenstette, Edward},
  journal={Transactions of the Association for Computational Linguistics},
  volume={6},
  pages={317--328},
  year={2018},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~â€¦}
}

@inproceedings{ho-etal-2020-constructing,
    title = "Constructing A Multi-hop {QA} Dataset for Comprehensive Evaluation of Reasoning Steps",
    author = "Ho, Xanh  and
      Duong Nguyen, Anh-Khoa  and
      Sugawara, Saku  and
      Aizawa, Akiko",
    editor = "Scott, Donia  and
      Bel, Nuria  and
      Zong, Chengqing",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.580/",
    doi = "10.18653/v1/2020.coling-main.580",
    pages = "6609--6625",
    abstract = "A multi-hop question answering (QA) dataset aims to test reasoning and inference skills by requiring a model to read multiple paragraphs to answer a given question. However, current datasets do not provide a complete explanation for the reasoning process from the question to the answer. Further, previous studies revealed that many examples in existing multi-hop datasets do not require multi-hop reasoning to answer a question. In this study, we present a new multi-hop QA dataset, called 2WikiMultiHopQA, which uses structured and unstructured data. In our dataset, we introduce the evidence information containing a reasoning path for multi-hop questions. The evidence information has two benefits: (i) providing a comprehensive explanation for predictions and (ii) evaluating the reasoning skills of a model. We carefully design a pipeline and a set of templates when generating a question-answer pair that guarantees the multi-hop steps and the quality of the questions. We also exploit the structured format in Wikidata and use logical rules to create questions that are natural but still require multi-hop reasoning. Through experiments, we demonstrate that our dataset is challenging for multi-hop models and it ensures that multi-hop reasoning is required."
}

@inproceedings{wang2024leave,
  title={Leave no document behind: Benchmarking long-context llms with extended multi-doc qa},
  author={Wang, Minzheng and Chen, Longze and Cheng, Fu and Liao, Shengyi and Zhang, Xinghua and Wu, Bingli and Yu, Haiyang and Xu, Nan and Zhang, Lei and Luo, Run and others},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={5627--5646},
  year={2024}
}

@inproceedings{hu2023meetingbank,
  title={Meetingbank: A benchmark dataset for meeting summarization},
  author={Hu, Yebowen and Ganter, Timothy and Deilamsalehy, Hanieh and Dernoncourt, Franck and Foroosh, Hassan and Liu, Fei},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={16409--16423},
  year={2023}
}

@article{tu2023characterchat,
  title={Characterchat: Learning towards conversational ai with personalized social support},
  author={Tu, Quan and Chen, Chuanqi and Li, Jinpeng and Li, Yanran and Shang, Shuo and Zhao, Dongyan and Wang, Ran and Yan, Rui},
  journal={arXiv preprint arXiv:2308.10278},
  year={2023}
}

@article{liu2023repobench,
  title={Repobench: Benchmarking repository-level code auto-completion systems},
  author={Liu, Tianyang and Xu, Canwen and McAuley, Julian},
  journal={arXiv preprint arXiv:2306.03091},
  year={2023}
}

@article{ding2023crosscodeeval,
  title={Crosscodeeval: A diverse and multilingual benchmark for cross-file code completion},
  author={Ding, Yangruibo and Wang, Zijian and Ahmad, Wasi and Ding, Hantian and Tan, Ming and Jain, Nihal and Ramanathan, Murali Krishna and Nallapati, Ramesh and Bhatia, Parminder and Roth, Dan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46701--46723},
  year={2023}
}

@article{chen2019tabfact,
  title={Tabfact: A large-scale dataset for table-based fact verification},
  author={Chen, Wenhu and Wang, Hongmin and Chen, Jianshu and Zhang, Yunkai and Wang, Hong and Li, Shiyang and Zhou, Xiyou and Wang, William Yang},
  journal={arXiv preprint arXiv:1909.02164},
  year={2019}
}

@article{kweon2023open,
  title={Open-wikitable: Dataset for open domain question answering with complex reasoning over table},
  author={Kweon, Sunjun and Kwon, Yeonsu and Cho, Seonhee and Jo, Yohan and Choi, Edward},
  journal={arXiv preprint arXiv:2305.07288},
  year={2023}
}

@inproceedings{bai2024longbench,
  title={Longbench: A bilingual, multitask benchmark for long context understanding},
  author={Bai, Yushi and Lv, Xin and Zhang, Jiajie and Lyu, Hongchang and Tang, Jiankai and Huang, Zhidian and Du, Zhengxiao and Liu, Xiao and Zeng, Aohan and Hou, Lei and others},
  booktitle={Proceedings of the 62nd annual meeting of the association for computational linguistics (volume 1: Long papers)},
  pages={3119--3137},
  year={2024}
}

@article{huang2021efficient,
  title={Efficient attentions for long document summarization},
  author={Huang, Luyang and Cao, Shuyang and Parulian, Nikolaus and Ji, Heng and Wang, Lu},
  journal={arXiv preprint arXiv:2104.02112},
  year={2021}
}

@inproceedings{fabbri2019multi,
  title={Multi-news: A large-scale multi-document summarization dataset and abstractive hierarchical model},
  author={Fabbri, Alexander Richard and Li, Irene and She, Tianwei and Li, Suyi and Radev, Dragomir},
  booktitle={Proceedings of the 57th annual meeting of the association for computational linguistics},
  pages={1074--1084},
  year={2019}
}

@article{shaham2023zeroscrolls,
  title={ZeroSCROLLS: A zero-shot benchmark for long text understanding},
  author={Shaham, Uri and Ivgi, Maor and Efrat, Avia and Berant, Jonathan and Levy, Omer},
  journal={arXiv preprint arXiv:2305.14196},
  year={2023}
}

@article{yan2025mir,
  title={MIR-Bench: Can Your LLM Recognize Complicated Patterns via Many-Shot In-Context Reasoning?},
  author={Yan, Kai and Ling, Zhan and Liu, Kang and Yang, Yifan and Fan, Ting-Han and Shen, Lingfeng and Du, Zhengyin and Chen, Jiecao},
  journal={arXiv preprint arXiv:2502.09933},
  year={2025}
}

@article{agarwal2024many,
  title={Many-shot in-context learning},
  author={Agarwal, Rishabh and Singh, Avi and Zhang, Lei and Bohnet, Bernd and Rosias, Luis and Chan, Stephanie and Zhang, Biao and Anand, Ankesh and Abbas, Zaheer and Nova, Azade and others},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={76930--76966},
  year={2024}
}

@article{hsieh2024ruler,
  title={RULER: What's the Real Context Size of Your Long-Context Language Models?},
  author={Hsieh, Cheng-Ping and Sun, Simeng and Kriman, Samuel and Acharya, Shantanu and Rekesh, Dima and Jia, Fei and Zhang, Yang and Ginsburg, Boris},
  journal={arXiv preprint arXiv:2404.06654},
  year={2024}
}

@article{kuratov2024babilong,
  title={Babilong: Testing the limits of llms with long context reasoning-in-a-haystack},
  author={Kuratov, Yury and Bulatov, Aydar and Anokhin, Petr and Rodkin, Ivan and Sorokin, Dmitry and Sorokin, Artyom and Burtsev, Mikhail},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={106519--106554},
  year={2024}
}

@inproceedings{chen2024benchmarking,
  title={Benchmarking large language models in retrieval-augmented generation},
  author={Chen, Jiawei and Lin, Hongyu and Han, Xianpei and Sun, Le},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={17754--17762},
  year={2024}
}

@article{friel2024ragbench,
  title={Ragbench: Explainable benchmark for retrieval-augmented generation systems},
  author={Friel, Robert and Belyi, Masha and Sanyal, Atindriyo},
  journal={arXiv preprint arXiv:2407.11005},
  year={2024}
}

@article{liu2023recall,
  title={Recall: A benchmark for llms robustness against external counterfactual knowledge},
  author={Liu, Yi and Huang, Lianzhe and Li, Shicheng and Chen, Sishuo and Zhou, Hao and Meng, Fandong and Zhou, Jie and Sun, Xu},
  journal={arXiv preprint arXiv:2311.08147},
  year={2023}
}

@article{thakur2021beir,
  title={Beir: A heterogenous benchmark for zero-shot evaluation of information retrieval models},
  author={Thakur, Nandan and Reimers, Nils and R{\"u}ckl{\'e}, Andreas and Srivastava, Abhishek and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2104.08663},
  year={2021}
}

@inproceedings{muennighoff2023mteb,
  title={Mteb: Massive text embedding benchmark},
  author={Muennighoff, Niklas and Tazi, Nouamane and Magne, Lo{\"\i}c and Reimers, Nils},
  booktitle={Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
  pages={2014--2037},
  year={2023}
}

@article{gao2023enabling,
  title={Enabling large language models to generate text with citations},
  author={Gao, Tianyu and Yen, Howard and Yu, Jiatong and Chen, Danqi},
  journal={arXiv preprint arXiv:2305.14627},
  year={2023}
}

@inproceedings{zhang2025longcite,
  title={Longcite: Enabling llms to generate fine-grained citations in long-context qa},
  author={Zhang, Jiajie and Bai, Yushi and Lv, Xin and Gu, Wanjun and Liu, Danqing and Zou, Minhao and Cao, Shulin and Hou, Lei and Dong, Yuxiao and Feng, Ling and others},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2025},
  pages={5098--5122},
  year={2025}
}

@article{yang2024gated,
  title={Gated delta networks: Improving mamba2 with delta rule},
  author={Yang, Songlin and Kautz, Jan and Hatamizadeh, Ali},
  journal={arXiv preprint arXiv:2412.06464},
  year={2024}
}

@article{wang2025opencua,
  title={Opencua: Open foundations for computer-use agents},
  author={Wang, Xinyuan and Wang, Bowen and Lu, Dunjie and Yang, Junlin and Xie, Tianbao and Wang, Junli and Deng, Jiaqi and Guo, Xiaole and Xu, Yiheng and Wu, Chen Henry and others},
  journal={arXiv preprint arXiv:2508.09123},
  year={2025}
}

@article{xie2025jedi,
  title={Scaling computer-use grounding via user interface decomposition and synthesis},
  author={Xie, Tianbao and Deng, Jiaqi and Li, Xiaochuan and Yang, Junlin and Wu, Haoyuan and Chen, Jixuan and Hu, Wenjing and Wang, Xinyuan and Xu, Yuhui and Wang, Zekun and others},
  journal={arXiv preprint arXiv:2505.13227},
  year={2025}
}

@article{li2024montessori,
  title={Montessori-instruct: Generate influential training data tailored for student learning},
  author={Li, Xiaochuan and Yu, Zichun and Xiong, Chenyan},
  journal={arXiv preprint arXiv:2410.14208},
  year={2024}
}